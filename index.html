<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A compact neuromorphic system for energy-efficient, on-device robot localization">
  <meta name="keywords" content="Visual place recognition, neuromorphic computing, spiking neural network">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LENS - Locational Encoding using Neuromorphic Systems</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/hexapod.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://www.qut.edu.au/research/centre-for-robotics">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          Related work
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://vprtempo.github.io">
            VPRTempo
          </a>
          <a class="navbar-item" href="https://github.com/Tobias-Fischer/sparse-event-vpr">
            Sparse Event VPR
          </a>
          <a class="navbar-item" href="https://www.nature.com/articles/s41467-024-47811-6">
            SynSense SPECK
          </a>
          <a class="navbar-item" href="https://github.com/QVPR/VPRSNN">
            VPRSNN
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">A compact neuromorphic system for energy-efficient, on-device robot localization</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://keunhong.com">Adam D Hines</a>,</span>
            <span class="author-block">
              <a href="https://utkarshsinha.com">Michael Milford</a>,</span>
            <span class="author-block">
              <a href="https://jonbarron.info">Tobias Fischer</a>,
            </span>
           
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">QUT Centre for Robotics, Brisbane QLD, Australia</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://google.com"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/AdamDHines/LENS"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="lens vid">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser1" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/lensvid.mp4" type="video/mp4">
      </video>
        <h2 class="subtitle has-text-centered">
        Real-time, event driven localization
      </h2>
    </div>
  </div>
</section>
  
<section class="robot vid">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser2" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/0808.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Multi-terrain, multi-envrionment deployment on a Hexapod robotic platform
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Autonomous robots need effective localization and environmental understanding for real-world deployment. 
            Visual place recognition is crucial for mapping and localizing positions but typically requires computationally 
            demanding models. We present a compact, efficient solution using neuromorphic computing inspired by the brain, 
            combining spiking neural networks, dynamic vision sensors, and a neuromorphic processor on a single SPECK™ chip.
            Our Locational Encoding with Neuromorphic Systems (LENS) can learn and recognize places with models over 99% smaller 
            than traditional systems, using less than 1% of the energy. Deployed on a Hexapod robot, LENS demonstrates real-time, 
            energy-efficient place recognition in varied environments, using fewer than 35k parameters to learn over 700 places. 
            This is one of the first fully neuromorphic systems for real-time large-scale localization on robotic platforms.
          </p>
          <p>

          </p>
          <p>

          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">SynSense SPECK™</h2>
          <p>
            Our system is a fully neuromorphic localization ecosystem
            on the SynSense SPECK™, a single chip event camera and SoC
            neuromorphic processor.
          </p>
          <img id="speck" src="./static/images/IMG_3593.jpg" alt="SynSense SPECK in a 3D printed housing" height="100%">

        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">Hexapod</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              We take our LENS system and deploy it on a Hexapod robotic platform
              for multi-terrain, multi-environment mapping and localization.
            </p>
            <img id="speck" src="./static/images/IMG_3558.jpg" alt="Hexapod robot" height="100%">
          </div>

        </div>
      </div>
    </div>
    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Performance</h2>

        <!-- Interpolating. -->
        <h3 class="title is-4">Energy efficiency</h3>
        <div class="content has-text-justified">
          <p>
            A key benefit of our system is the energy effeciency afforded
            by using neuromorphic hardware and sensors. LENS needs <1% the power
            required by conventional von Neumann CPUs.
          </p>
          <img id="energy" src="./static/images/power.png" alt="Energy effeciency metrics" height="100%">
        </div>
        <br/>
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <h3 class="title is-4">Localization in small and large scale environments</h3>
        <div class="content has-text-justified">
          <p>
            LENS shows impressive localization in both small and large scale environments.
            With model sizes smaller than 150 KB with just 35k parameters, the scalability
            of our system allows for place recognition for traversals up to 8km.
          </p>
        </div>
        <div class="content has-text-centered">
          <img id="localization" src="./static/images/indooroutdoor.png" alt="Localization performance" height="100%">
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            This work was developed as an extension to a variety of excellent work in robotic localization.
          </p>
          <p>
            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9925670">Sparse event VPR</a> develops the concept of using small number of event pixels to perform accurate localization.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2311.13186">VPRSNN</a> introduced one of the first spiking neural networks for visual place recognition, 
            which inspired previous work for an efficiently trained and inferenced network <a href="https://arxiv.org/abs/2309.10225">VPRTempo</a>,
            which was adapted for this work.
          </p>
          <p>
            In addition to this, a lot of great work has been done in the localization and navigation field using neuromorphic hardware.
          </p>
          <p>
            <a href="https://www.science.org/doi/full/10.1126/scirobotics.abm6996">Fangwen Yu's work</a> developed an impressive multi-modal neural network for accurate place recognition.
            <a href="https://www.science.org/doi/10.1126/scirobotics.adg3679">Le Zhu</a> pioneered sequence learning using event cameras through vegetative environments.
            <a href="https://www.science.org/doi/10.1126/scirobotics.adk0310">Tom van Dijk</a> deployed an impressively compact neuromorphic system on a tiny autonomous drone for visual route following.
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{hines2024compactneuromorphicultraenergyefficient,
      title={A compact neuromorphic system for ultra energy-efficient, on-device robot localization}, 
      author={Adam D. Hines and Michael Milford and Tobias Fischer},
      year={2024},
      eprint={2408.16754},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2408.16754}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Please see the following for the source code of this website <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
